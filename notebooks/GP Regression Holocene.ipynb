{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import arviz as az\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "import sys\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "from bahamas_lig.utils import *\n",
    "\n",
    "model_dir = PROJECT_ROOT / \"model_outputs/\"\n",
    "inference_dir = PROJECT_ROOT / \"model_outputs/holocene\"\n",
    "data_dir = PROJECT_ROOT / \"data/\"\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display\n",
    "from ipywidgets import Button, HBox, VBox, Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following javascript cell runs bottom the cell of notebook to define some helper functions and force refresh the IPython displays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.execute_cells([-1,-5,-4,-3])\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript \n",
    "Jupyter.notebook.execute_cells([-1,-5,-4,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select models to inspect:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231f8ecd8efb4f6585b72604851a8f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Lithosphere'), SelectMultiple(layout=Layout(height='16vh', width='5…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a690dc6c154431a1cfe60debb4c78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Plot weighted inference for selected', layout=Layout(width='33%'), style=Bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Select models to inspect:\")\n",
    "display(h_box)\n",
    "display(HBox(buttons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed0178288854426bb2f09cd5efb386e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output_simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8c0988396743fd8ffdf4c7192ffde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(filtered_df_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and widget definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     8,
     20,
     37,
     91,
     109,
     191,
     202,
     211,
     219,
     227,
     236,
     244,
     252,
     260,
     264,
     268,
     279
    ]
   },
   "outputs": [],
   "source": [
    "def load_holocene_data():\n",
    "    \n",
    "    data = pd.read_csv(data_dir / \"processed/gmsl_holocene_data.csv\")\n",
    "    data['age'] = data['age']/1000\n",
    "    data['age_uncertainty'] = data['age_uncertainty']/1000\n",
    "\n",
    "    return data\n",
    "\n",
    "def clear_and_run(click):\n",
    "    samp=samples_slider.value\n",
    "    accept=accept_slider.value\n",
    "    output_simulation.clear_output()\n",
    "    with output_simulation:     \n",
    "        to_run = list(models_df.query(\n",
    "                    f\"posterior_trace == {list(widge_post.value)} & posterior_predict == {list(widge_predict.value)} & Lithosphere == {list(widge_lith.value)} & UMV == {list(widge_umv.value)} & LMV == {list(widge_lmv.value)} & `ice_history` == {list(widge_ice.value)} & esl_curve == {list(widge_gmsl.value)}\"\n",
    "                ).index)\n",
    "    \n",
    "        backup(to_run)\n",
    "        run_inferences(to_run,samp,accept)\n",
    "        \n",
    "def plot_on_click(click):\n",
    "    models_df = get_model_status(inference_dir,model_dir/'get_GIA/output_Hol_new/')\n",
    "    output_simulation.clear_output(wait=True)\n",
    "    with output_simulation: \n",
    "        filtdb=models_df.query(\n",
    "                    f\"posterior_trace == {list(widge_post.value)} & posterior_predict == {list(widge_predict.value)} & Lithosphere == {list(widge_lith.value)} & UMV == {list(widge_umv.value)} & LMV == {list(widge_lmv.value)} & `ice_history` == {list(widge_ice.value)} & esl_curve == {list(widge_gmsl.value)}\")\n",
    "                \n",
    "        to_run = list(filtdb.index)\n",
    "        \n",
    "        if any(filtdb['posterior_trace']==False):\n",
    "            print('Selected models have no traces, please run inference and generate weights..')\n",
    "            return None\n",
    "            \n",
    "        fig=weighted_inference_plot(to_run)\n",
    "        plt.show()\n",
    "    return\n",
    "    \n",
    "def backup(to_run):\n",
    "    \n",
    "\n",
    "        for f in to_run:\n",
    "            try:\n",
    "                model_posterior_dir = str(inference_dir)+'/'+str('arviz_traces_2021')\n",
    "                os.rename(model_posterior_dir+'/'+f+'.nc', \n",
    "                          model_posterior_dir+'_backup/'+f+'.nc')\n",
    "                model_predict_dir = str(inference_dir)+'/'+str('pymc3_post_predict_2021')\n",
    "                os.rename(model_predict_dir+'/'+f+'.pkl', \n",
    "                          model_predict_dir+'_backup/'+f+'.pkl')\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "def run_inferences(to_run,samp,accept):\n",
    "\n",
    "    data2 = load_holocene_data()\n",
    "    N = data2[\"elevation\"].size\n",
    "    data2=data2.sort_values(['type'])\n",
    "    keys = list(data2['type'].unique())\n",
    "    \n",
    "\n",
    "    count=1\n",
    "\n",
    "    for m in to_run:\n",
    "        clear_output(wait=True)\n",
    "        print(\"running simulation number \" + str(count) + \" of \" + str(len(to_run)))\n",
    "        print(\"running model: \" + m)\n",
    "        count+=1\n",
    "        model_name = m\n",
    "\n",
    "        ## Build the statistical model\n",
    "        GIA_MODEL, age, model_dims = load_model(m, rsl_dir = 'output_Hol_new')\n",
    "        GIA_MODEL = [GIA_MODEL[a] for a in np.argsort(age)]\n",
    "        age = np.sort(age)\n",
    "        z_functions = interpolation_functions(data2[\"lat\"], data2[\"lon\"], GIA_MODEL, age, model_dims)\n",
    "        model, gp = inference_model(data2,z_functions,keys=keys,holocene=True)\n",
    "        \n",
    "        with model:\n",
    "            ## The Hamiltonian Monte-Carlo sampling step, ie the inference button\n",
    "            az_trace = pm.sample(tune=samp,draws=samp,\n",
    "                    init='adapt_full', progressbar=True, cores=1, target_accept=accept, chains=1, \n",
    "                              return_inferencedata=True\n",
    "                )\n",
    "\n",
    "            #### After fitting, lets save our hard work\n",
    "            \n",
    "            ## and we will collect our hard work in this subfolders\n",
    "            model_posterior_dir = str(inference_dir)+'/'+str('arviz_traces_2021/')\n",
    "            model_predict_dir = str(inference_dir)+'/'+str('pymc3_post_predict_2021/')\n",
    "\n",
    "            az_trace.to_netcdf(model_posterior_dir+model_name+'.nc',groups=[\"posterior\",\"log_likelihood\"])\n",
    "            print('Success')\n",
    "        \n",
    "def re_weight(click):\n",
    "    \n",
    "    filtered_df_output.clear_output()\n",
    "    with filtered_df_output:\n",
    "        print('Recalculating model weights...')\n",
    "    \n",
    "    model_posterior_dir = str(inference_dir)+'/'+str('arviz_traces_2021')\n",
    "    model_posterior_list=[o[:-3] for o in os.listdir(model_posterior_dir) if '.nc' in o]    \n",
    "\n",
    "    all_traces = {}\n",
    "    for f in model_posterior_list:\n",
    "        all_traces[f]=az.from_netcdf(model_posterior_dir+'/'+f+'.nc')\n",
    "\n",
    "    comp = az.compare(all_traces, ic=\"loo\", method='BB-pseudo-BMA', b_samples=50000, alpha=1) \n",
    "    comp.to_csv(str(inference_dir)+'/'+str('model_weights/model_weights.csv'))\n",
    "    \n",
    "    update_table(click)\n",
    "\n",
    "def weighted_inference_plot(to_run):\n",
    "    \n",
    "    if type(to_run)!=type([]):\n",
    "        to_run=[to_run]\n",
    "    \n",
    "    model_predict_dir = str(inference_dir)+'/'+str('pymc3_post_predict_2021')\n",
    "    model_predict_list=[o[:-4] for o in os.listdir(model_predict_dir) if '.pkl' in o]\n",
    "    \n",
    "    preds = {}\n",
    "    for f in to_run:\n",
    "        if f in model_predict_list:\n",
    "            preds[f]=load(model_predict_dir+'/'+f+'.pkl')\n",
    "            \n",
    "    if len(preds.keys())==0:\n",
    "        print('Selected models have no traces, please run inference and generate weights..')\n",
    "        return None\n",
    "\n",
    "    model_weights = pd.read_csv(str(model_dir)+'/'+str('model_weights/model_weights.csv'),index_col=0)\n",
    "    sub_list=[m for m in to_run if m in list(model_weights.index)]\n",
    "    model_weights=model_weights.loc[sub_list]\n",
    "    if np.sum(model_weights['weight'])==0:\n",
    "        model_weights['weight']=1\n",
    "    else:\n",
    "        model_weights['weight']=model_weights['weight']/np.sum(model_weights['weight'])\n",
    "\n",
    "    gmsl=weighted_trace(preds,model_weights,iters=10000)\n",
    "\n",
    "    X_new = np.linspace(115, 130, 200)[:, np.newaxis]\n",
    "\n",
    "    f_size=18\n",
    "\n",
    "    sns.set_style(\n",
    "        \"ticks\",\n",
    "        {\n",
    "            \"axes.edgecolor\": \".3\",\n",
    "            \"xtick.color\": \".3\",\n",
    "            \"ytick.color\": \".3\",\n",
    "            \"text.color\": \".3\",\n",
    "            \"axes.facecolor\": \"(.98,.98,.98)\",\n",
    "            \"axes.grid\": True,\n",
    "            \"grid.color\": \".95\",\n",
    "            \"grid.linestyle\": u\"--\",\n",
    "        },\n",
    "    )\n",
    "    flatui = [\"#D08770\", \"#BF616A\", \"#A3BE8C\", \"#B48EAD\", \"#34495e\", \"#5E81AC\"]\n",
    "    cs = sns.color_palette(flatui)\n",
    "\n",
    "    ##Figure\n",
    "\n",
    "    scale=1.5\n",
    "    fig = plt.figure(figsize=(11*scale,4*scale))\n",
    "    ax1=fig.add_subplot()\n",
    "\n",
    "    plot_gmsl_inference(X_new,gmsl,cs[4],ax1,False)\n",
    "    plt.gca().set_title(\n",
    "        \"A. Last Interglacial GMSL\",\n",
    "        fontsize=f_size,\n",
    "    )\n",
    "    ax1.set_aspect(1/2)\n",
    "    ax1.set_ylim([-2, 6])\n",
    "    # ax1.set_yticks([-2,0,2,4,6])\n",
    "    # ax1.set_yticklabels([-2,0,2,4,6],fontsize=f_size)\n",
    "    ax1.set_xlim(117, 128)\n",
    "    ax1.invert_xaxis()\n",
    "    ax1.set_xticks(np.arange(128,116,-1))\n",
    "    ax1.set_xticklabels(np.arange(128,116,-1),fontsize=f_size)\n",
    "    ax1.legend(loc=\"best\", frameon=True, fontsize=f_size*.66)\n",
    "\n",
    "    ax1.set_ylabel(\"Global Mean Sea Level\\n(m above MSL)\", fontsize=f_size)\n",
    "    ax1.set_xlabel(\"Age (kya)\",fontsize=f_size)\n",
    "    ax1.grid(linewidth=1)\n",
    "\n",
    "\n",
    "    fig.tight_layout(w_pad=0,h_pad=0)\n",
    "    return fig\n",
    "\n",
    "models_df = get_model_status(inference_dir,model_dir/'get_GIA/output_Hol_new/')\n",
    "fmt = Layout(width=\"5vw\", height=\"16vh\")\n",
    "filtered_df_output = widgets.Output()\n",
    "output_simulation = widgets.Output()\n",
    "\n",
    "\n",
    "def update_table(change):\n",
    "    models_df = get_model_status(inference_dir,model_dir/'get_GIA/output_Hol_new/')\n",
    "    filtered_df_output.clear_output(wait=True)\n",
    "    with filtered_df_output:\n",
    "        display(\n",
    "            models_df.query(\n",
    "                f\"posterior_trace == {list(widge_post.value)} & posterior_predict == {list(widge_predict.value)} & Lithosphere == {list(widge_lith.value)} & UMV == {list(widge_umv.value)} & LMV == {list(widge_lmv.value)} & `ice_history` == {list(widge_ice.value)} & esl_curve == {list(widge_gmsl.value)}\"\n",
    "            ).sort_values('weight',ascending=False)\n",
    "        )\n",
    "\n",
    "\n",
    "widge_lith = widgets.SelectMultiple(\n",
    "    options=np.sort(models_df[\"Lithosphere\"].unique().astype(int)),\n",
    "    # rows=10,\n",
    "    #     description=\"Lithosphere\",\n",
    "    disabled=False,\n",
    "    layout=fmt,\n",
    ")\n",
    "\n",
    "\n",
    "widge_umv = widgets.SelectMultiple(\n",
    "    options=np.sort(models_df[\"UMV\"].unique().astype(int)),\n",
    "    # rows=10,\n",
    "    #     description=\"UMV\",\n",
    "    disabled=False,\n",
    "    layout=fmt,\n",
    ")\n",
    "\n",
    "widge_lmv = widgets.SelectMultiple(\n",
    "    options=np.sort(models_df[\"LMV\"].unique().astype(int)),\n",
    "    # rows=10,\n",
    "    #     description=\"LMV\",\n",
    "    disabled=False,\n",
    "    layout=fmt,\n",
    ")\n",
    "\n",
    "widge_ice = widgets.SelectMultiple(\n",
    "    options=models_df[\"ice_history\"].unique(),\n",
    "    # rows=10,\n",
    "    #     description=\"Ice History\",\n",
    "    disabled=False,\n",
    "    layout=fmt,\n",
    ")\n",
    "\n",
    "\n",
    "widge_gmsl = widgets.SelectMultiple(\n",
    "    options=models_df[\"esl_curve\"].unique(),\n",
    "    # rows=10,\n",
    "    #     description=\"GMSL\",\n",
    "    disabled=False,\n",
    "    layout=fmt,\n",
    ")\n",
    "\n",
    "widge_post = widgets.SelectMultiple(\n",
    "    options=[True, False],\n",
    "    # rows=10,\n",
    "    #     description=\"Posterior Trace\",\n",
    "    disabled=False,\n",
    "    layout=fmt,\n",
    ")\n",
    "\n",
    "widge_predict = widgets.SelectMultiple(\n",
    "    options=[True, False],\n",
    "    # rows=10,\n",
    "    #     description=\"Posterior Prediction\",\n",
    "    disabled=False,\n",
    "    layout=fmt,\n",
    ")\n",
    "\n",
    "samples_slider=widgets.IntSlider(value=500,\n",
    "    min=100,step=50,\n",
    "    max=2000,layout=fmt,orientation='vertical')\n",
    "\n",
    "accept_slider=widgets.FloatSlider(value=.95,\n",
    "    min=.8,step=0.01,\n",
    "    max=1,layout=fmt,orientation='vertical')\n",
    "\n",
    "label_list = [\n",
    "    \"Lithosphere\",\n",
    "    \"UMV\",\n",
    "    \"LMV\",\n",
    "    \"ice_history\",\n",
    "    \"esl_curve\",\n",
    "    \"posterior_trace\",\n",
    "    \"posterior_prediction\",\n",
    "    \"Posterior samples\",\n",
    "    \"Acceptance Target\"\n",
    "]\n",
    "widget_list = [\n",
    "    widge_lith,\n",
    "    widge_umv,\n",
    "    widge_lmv,\n",
    "    widge_ice,\n",
    "    widge_gmsl,\n",
    "    widge_post,\n",
    "    widge_predict,\n",
    "    samples_slider,\n",
    "    accept_slider\n",
    "]\n",
    "\n",
    "wv_list = [VBox([Label(l), w]) for l, w in zip(label_list, widget_list)]\n",
    "h_box = HBox(wv_list)\n",
    "\n",
    "for w in widget_list:\n",
    "    w.observe(update_table)\n",
    "\n",
    "N_button = 3\n",
    "pct = 100 / N_button\n",
    "bt_layout = Layout(width=str(int(pct)) + \"%\")\n",
    "plot_inference_button = Button(\n",
    "    description=\"Plot weighted inference for selected\", layout=bt_layout\n",
    ")\n",
    "rerun_weights = Button(description=\"Recalculate weights for all\", layout=bt_layout)\n",
    "rerun_inference_button = Button(\n",
    "    description=\"Rerun GMSL inference for selected\", layout=bt_layout\n",
    ")\n",
    "\n",
    "plot_inference_button.on_click(plot_on_click)\n",
    "rerun_weights.on_click(re_weight)\n",
    "rerun_inference_button.on_click(clear_and_run)\n",
    "\n",
    "buttons = [plot_inference_button, rerun_weights, rerun_inference_button]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bahamas_lig",
   "language": "python",
   "name": "bahamas_lig"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
